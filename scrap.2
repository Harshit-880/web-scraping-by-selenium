import json
from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
import re
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# Setup Chrome options
chrome_options = Options()
chrome_options.add_argument("--headless")  # Ensure GUI is off
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")

# Set path to chromedriver as per your configuration
# webdriver_service = Service('/path/to/chromedriver')  # Change this to your ChromeDriver path

# Choose Chrome Browser
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
# URL of the CoinMarketCap page for DUKO
url = "https://coinmarketcap.com/currencies/bitcoin-cash/"

# Open the URL
driver.get(url)

# Wait for elements to load
# wait = WebDriverWait(driver, 10)

# Extract the necessary data points
coin = "solana"

price_element = driver.find_element('xpath','/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/section/div/div[2]/span')
price = float(price_element.text.replace('$', '').replace(',', ''))

price_change_element = driver.find_element('xpath','/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/section/div/div[2]/div/div/p')
price_change_text = price_change_element.text

# Use regular expression to extract only the numerical part
price_change_numeric = re.search(r'[-+]?\d*\.\d+|\d+', price_change_text).group()

# Convert the extracted numerical part to a float
price_change = float(price_change_numeric)

market_cap_element = driver.find_element('xpath','/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[1]/div/dl/div[1]/div[1]/dd')
text_market = market_cap_element.text
market_cap = text_market.split('$')[1].replace(',', '')


market_cap_rank_element = driver.find_element('xpath','/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[1]/div/dl/div[1]/div[2]/div/span')
market_cap_rank = int(market_cap_rank_element.text.split('#')[1])

volume_element = driver.find_element('xpath','/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[1]/div/dl/div[2]/div[1]/dd')
text_volume = volume_element.text
volume = text_volume.split('$')[1].replace(',', '')

volume_rank_element = driver.find_element('xpath','/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[1]/div/dl/div[2]/div[2]/div/span')
volume_rank = int(volume_rank_element.text.split('#')[1])

volume_change_element = driver.find_element('xpath','/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[1]/div/dl/div[3]/div/dd')
volume_change = float(volume_change_element.text.replace('%', '').replace(',', ''))

circulating_supply_element = driver.find_element('xpath','//html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[1]/div/dl/div[4]/div/dd')
circulating_supply = int(circulating_supply_element.text.split(' ')[0].replace(',', ''))

total_supply_element = driver.find_element('xpath','/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[1]/div/dl/div[5]/div/dd')
total_supply = int(total_supply_element.text.split(' ')[0].replace(',', ''))

diluted_market_cap_element=driver.find_element('xpath','/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[1]/div/dl/div[7]/div/dd')
diluted_market_cap = int(diluted_market_cap_element.text.replace('$', '').replace(',', ''))

# /html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[2]/div[1] of contract 
# /html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[2]/div[2]of official
# /html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[2]/div[1] of official
# Adjust the XPath based on the presence of the "Contracts" section
# Adjust the XPath based on the presence of the "Contracts" section
try:
    contracts_header = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[2]/div[1]/div[1]/span'))
    )
    check_test = contracts_header.text
except:
    check_test = ""
# Set the initial value of i
i = 0
if check_test == "Contracts":
    i = 1

print("gfuiergkjdkjjb")
print(i)
# Extract official links
official_links = []
try:
    official_links_container = driver.find_elements('xpath', f'/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[2]/div[{1 + i}]/div[2]/div/div')
    for element in official_links_container:
        try:
            link_element = element.find_element('tag name', 'a')
            official_links.append({
                "name": element.text.strip(),
                "link": link_element.get_attribute("href")
            })
        except:
            continue
except:
    pass

# Extract social links
socials = []
try:
    social_elements = driver.find_elements('xpath', f'/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[2]/div[{2 + i}]/div[2]/div/div')
    if social_elements:
        for element in social_elements:
            try:
                link_element = element.find_element('tag name', 'a')
                socials.append({
                    "name": element.text.strip(),
                    "url": link_element.get_attribute("href")
                })
            except:
                continue
    else:
        # Fallback to single social link case
        single_social_element = driver.find_element('xpath', f'/html/body/div[1]/div[2]/div/div[2]/div/div/div[2]/div[2]/section[2]/div/div[2]/div[{3 + i}]/div[2]/div/div')
        link_element = single_social_element.find_element('tag name', 'a')
        socials.append({
            "name": single_social_element.text.strip(),
            "url": link_element.get_attribute("href")
        })
except:
    pass

# Rest of your code remains the same

# Compile all data into a dictionary
data = {
    "coin": coin,
    "output": {
        "price": price,
        "price_change": price_change,
        "market_cap": market_cap,
        "market_cap_rank": market_cap_rank,
        "volume": volume,
        "volume_rank": volume_rank,
        "volume_change": volume_change,
        "circulating_supply": circulating_supply,
        "total_supply": total_supply,
        "diluted_market_cap": diluted_market_cap,
        # "contracts": contracts,
        "official_links": official_links,
        "socials": socials
    }
}

# Print the JSON data
print(json.dumps(data, indent=4))

# Close the browser
driver.quit()

